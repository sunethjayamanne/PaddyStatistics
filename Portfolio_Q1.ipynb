{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8189ed26-cb4d-4589-baf2-d43748d31585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset uploaded to GCS bucket 'paddy_statistics' as 'paddy_statistics_1952_2015.csv'!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "import os\n",
    "\n",
    "# Onjective of this program is to extract data from given URL using web scraping and save csv version of that data set in the Google cloud \n",
    "# ----------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Step 1: Web Scraping \n",
    "\n",
    "# used below URL of the web page to extract data \n",
    "url = \"https://www.statistics.gov.lk/Agriculture/StaticalInformation/PaddyStatistics/Annual-BothSeasons-1952-2015\"\n",
    "\n",
    "# Web Scraping \n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # Check for request errors\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "tables = soup.find_all('table')\n",
    "table = tables[-1]  # Last Table taken to eliminate unwanted dats set \n",
    "\n",
    "# Extract table data\n",
    "data = []\n",
    "for row in table.find_all('tr'):\n",
    "    cells = row.find_all(['th', 'td'])\n",
    "    cell_data = [cell.get_text(strip=True) for cell in cells]\n",
    "    if len(cell_data) > 3:  # Filter out unwanted rows\n",
    "        data.append(cell_data)\n",
    "\n",
    "# Ensure rows have equal columns\n",
    "max_columns = max(len(row) for row in data)\n",
    "for row in data:\n",
    "    row += [\"\"] * (max_columns - len(row))  # Fill missing cells with empty strings\n",
    "\n",
    "# Create DataFrame and set first row as header\n",
    "df = pd.DataFrame(data[1:], columns=data[0])\n",
    "\n",
    "# Convert DataFrame to CSV string\n",
    "csv_data = df.to_csv(index=False)\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------------------\n",
    "# Setp 2 - Upload csv file to Google Cloud\n",
    "\n",
    "# Google Cloud authentication\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"C:/Users/suneth.jayamanne/msc-project-portfolio-8c9eb0909b58.json\"\n",
    "\n",
    "# Initialize Google Cloud Storage client\n",
    "client = storage.Client()\n",
    "\n",
    "# Define bucket and destination filename\n",
    "bucket_name = \"paddy_statistics\"  \n",
    "destination_blob_name = \"paddy_statistics_1952_2015.csv\"\n",
    "\n",
    "# Upload the data to the Google Cloud Storage\n",
    "bucket = client.bucket(bucket_name)\n",
    "blob = bucket.blob(destination_blob_name)\n",
    "blob.upload_from_string(csv_data, content_type='text/csv')\n",
    "\n",
    "print(f\"Dataset uploaded to GCS bucket '{bucket_name}' as '{destination_blob_name}'!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "220a21c3-8b48-4502-819f-7a0898ab2135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded from GCS to 'D:/Personal/MSc/MSc. Data Science/Lecture Notes/2. Principles of DS/Assignment and Passpapers/Assignments/Portfolio/paddy_statistics_1952_2015_downloaded.csv'\n"
     ]
    }
   ],
   "source": [
    "# Step 3 - Download the file from GCS to working folder \n",
    "\n",
    "downloaded_file_path = \"D:/Personal/MSc/MSc. Data Science/Lecture Notes/2. Principles of DS/Assignment and Passpapers/Assignments/Portfolio/paddy_statistics_1952_2015_downloaded.csv\"\n",
    "blob.download_to_filename(downloaded_file_path)\n",
    "print(f\"File downloaded from GCS to '{downloaded_file_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3ba8a0d2-dfbb-4378-b382-8e2f6a914452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleansed file loaded\n"
     ]
    }
   ],
   "source": [
    "# Step 4 - Load the cleansed file to do EDA\n",
    "file_path = \"D:/Personal/MSc/MSc. Data Science/Lecture Notes/2. Principles of DS/Assignment and Passpapers/Assignments/Portfolio/paddy_statistics_1952_2015_cleansed.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"cleansed file loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d34492d-6103-45d4-8eba-381956f27055",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
